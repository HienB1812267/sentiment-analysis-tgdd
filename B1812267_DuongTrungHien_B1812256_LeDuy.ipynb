{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0DOyCbeT0Xi"
      },
      "source": [
        "#Install thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4LnZb4PEJbUG",
        "outputId": "beaeda57-c081-4156-ab42-dfdb4e4b290f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 18.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 454 kB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 24.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 20.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 4.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=d8b1e15f9a9ac63b881bf274876f9db0c026f08949a9e8bb9ef466365a10a36f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n",
            "--2021-12-24 07:05:00--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 65.8.56.110, 65.8.56.12, 65.8.56.119, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|65.8.56.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322405979 (307M) [application/x-tar]\n",
            "Saving to: ‘PhoBERT_base_transformers.tar.gz’\n",
            "\n",
            "PhoBERT_base_transf 100%[===================>] 307.47M  91.1MB/s    in 3.4s    \n",
            "\n",
            "2021-12-24 07:05:05 (89.3 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n",
            "\n",
            "PhoBERT_base_transformers/\n",
            "PhoBERT_base_transformers/config.json\n",
            "PhoBERT_base_transformers/bpe.codes\n",
            "PhoBERT_base_transformers/model.bin\n",
            "PhoBERT_base_transformers/dict.txt\n",
            "Collecting fastBPE\n",
            "  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n",
            "Building wheels for collected packages: fastBPE\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=483115 sha256=b4257c55d1ae832749edf0bebdeb9712b67e6d46044ceb99158128cfa602d5de\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n",
            "Successfully built fastBPE\n",
            "Installing collected packages: fastBPE\n",
            "Successfully installed fastBPE-0.1.0\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.19.5)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.24)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.4.0)\n",
            "Collecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.1.*->hydra-core->fairseq) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (3.10.0.2)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=99dd522093a4479adca2888a5c7010078ff3e8a1fafac668b7430c12d2ea0ef0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.1 omegaconf-2.1.1 portalocker-2.3.2 sacrebleu-2.0.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pyvi\n",
        "!pip install transformers\n",
        "# !pip install deplacy vncorenlp\n",
        "# !test -d VnCoreNLP || git clone --depth=1 https://github.com/vncorenlp/VnCoreNLP\n",
        "!pip install emoji\n",
        "!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
        "!tar -xzvf PhoBERT_base_transformers.tar.gz\n",
        "!pip install fastBPE\n",
        "!pip install fairseq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BAk93l-Tu6C"
      },
      "source": [
        "#Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htncCdhKTuM5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from pyvi import ViTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0jbxnMiT4Hy"
      },
      "source": [
        "#Đọc file và datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ccLR427mCZI"
      },
      "outputs": [],
      "source": [
        "#Đọc dữ liệu từ file json, xóa bỏ cột name vì cột này không giúp cho việc huấn luyện mô hình\n",
        "df = pd.read_json('./static/data_TGDD.json')\n",
        "# df = df.drop(columns={'name'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQtxnVtxV97t"
      },
      "outputs": [],
      "source": [
        "#Đọc các stopwords từ file \n",
        "stopwords = []\n",
        "stopwords = list(open(\"./data/stopwords-nlp-vi.txt\", encoding=\"UTF-8-sig\", mode=\"r\"))\n",
        "for i in range(len(stopwords)):\n",
        "  stopwords[i] = re.sub(\"\\n\", \"\", stopwords[i])\n",
        "\n",
        "#Đọc các từ viết tắt từ file sang dict\n",
        "\n",
        "f = pd.read_csv(\"./data/acronym_vi.txt\", sep=\"\\t\").to_numpy()\n",
        "acronyms = {line[0]:line[1] for line in f}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf_fjkIamM9d"
      },
      "source": [
        "#Hiển thị dữ liệu (Visualization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bnKuQtMGmaVg",
        "outputId": "2fb7dcd7-6e34-4001-e9ff-25bffb559539"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57232e9f-7824-4c03-b3bf-03ba429fdb40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>content</th>\n",
              "      <th>star</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nhinhi</td>\n",
              "      <td>Mua được 2 tháng. Mà sao thấy chụp ảnh nó xấu ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tân</td>\n",
              "      <td>bắt wifi tệ chưa từng đang xài muốn ngắt là n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vũ Đình An</td>\n",
              "      <td>Mình mua trả góp gói 30% của FE lãi suất 0%.\\n...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nhi</td>\n",
              "      <td>màn hình mượt nhé lướt mượt kh có gì phải chê ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nguyễn Đức Tuyển</td>\n",
              "      <td>Cảm nhận khi mua sp\\nThiết kế đẹp\\nCấu hình mạ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19810</th>\n",
              "      <td>TRần Thị QUỲNH nGân</td>\n",
              "      <td>tân sinh viên thì thủ tục như thế nào vậy ạ .....</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19811</th>\n",
              "      <td>Thái</td>\n",
              "      <td>Mình học lớp 9 thì có được khuyến mãi khi mua ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19812</th>\n",
              "      <td>Phan Giang Thươg</td>\n",
              "      <td>Ưu đãi cho sinh viên thì thủ tục như thế nào. ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19813</th>\n",
              "      <td>Phùng Đạt</td>\n",
              "      <td>Loại này chơi game được ko, ví dụ game liên mi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19814</th>\n",
              "      <td>Phan Công Dũng</td>\n",
              "      <td>Loại này còn hàng ở Đà Nẵng ko ạ?\\nRam có thể ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19815 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57232e9f-7824-4c03-b3bf-03ba429fdb40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57232e9f-7824-4c03-b3bf-03ba429fdb40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57232e9f-7824-4c03-b3bf-03ba429fdb40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                      name  ... star\n",
              "0                   Nhinhi  ...    3\n",
              "1                      Tân  ...    1\n",
              "2               Vũ Đình An  ...    5\n",
              "3                      nhi  ...    3\n",
              "4         Nguyễn Đức Tuyển  ...    4\n",
              "...                    ...  ...  ...\n",
              "19810  TRần Thị QUỲNH nGân  ...    5\n",
              "19811                 Thái  ...    5\n",
              "19812     Phan Giang Thươg  ...    3\n",
              "19813            Phùng Đạt  ...    5\n",
              "19814       Phan Công Dũng  ...    5\n",
              "\n",
              "[19815 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiMbVV9Amo6L",
        "outputId": "92d667bb-e78f-4224-a7fc-4e6caae018af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5    7697\n",
              "3    3464\n",
              "1    3348\n",
              "4    3011\n",
              "2    2295\n",
              "Name: star, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Hiển thị số lượng bình luận của từng loại đánh giá\n",
        "df.star.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcAkjkYdOswz",
        "outputId": "f17bef8b-65c8-4e65-8cd2-da01627d4228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10708"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "7697 + 3011"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "u1jh3ayAmvEs",
        "outputId": "efb78d71-df70-4f8f-d8e3-72495f856619"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số lượng phần tử của từng nhãn\n"
          ]
        }
      ],
      "source": [
        "df.star.value_counts().plot(kind=\"bar\", color=[\"brown\", \"salmon\"])\n",
        "plt.show()\n",
        "porc = (len(df[df.star==1]) / len(df.star)) * 100\n",
        "print('Số lượng phần tử của từng nhãn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWspCQ9nXXG"
      },
      "source": [
        "Nhận xét: Tập dữ liệu không cân bằng: Vì có sự chênh lệch lớn giữa nhãn có giá trị là 5 so với các nhãn còn lại.\n",
        "Kết luận: Gộp nhãn có giá trị 5 và 4 lại là nhãn đánh giá tích cực (nhãn 1). Nhãn có giá trị 1,2 và 3 thành nhãn đánh giá tiêu cực (nhãn 0).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVekvAAVoPcH"
      },
      "source": [
        "Chuyển đổi nhãn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ha7qZdiCpCdr",
        "outputId": "5af30257-adc8-43c4-9eee-3929f9b613f8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phần trăm giữa tỉ lệ nhãn 1 và 0: 54.04%\n"
          ]
        }
      ],
      "source": [
        "def change_label(star):\n",
        "    if star <= 3:\n",
        "        return 0\n",
        "    return 1\n",
        "    \n",
        "#Chuyển đổi nhãn thành 0: tiêu cực và 1: tích cực\n",
        "df['label'] = df['star'].apply(change_label)\n",
        "\n",
        "df.label.value_counts().plot(kind=\"bar\", color=[\"brown\", \"salmon\"])\n",
        "plt.show()\n",
        "porc = (len(df[df.label==1]) / len(df.label)) * 100\n",
        "print('Phần trăm giữa tỉ lệ nhãn 1 và 0: {:.2f}%'.format(porc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XePp25_Up_DH"
      },
      "source": [
        "Nhận xét: Tập dữ liệu phân bố theo: (54:46) hay (6:4) => Tập dữ không quá mất cân bằng, không ảnh hưởng đáng kể tới kết quả dự đoán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBe1OXwz3YId"
      },
      "source": [
        "URL tham khảo: https://www.kaggle.com/vbmokin/nlp-eda-bag-of-words-tf-idf-glove-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilC7rKXasb10"
      },
      "outputs": [],
      "source": [
        "def length(text):    \n",
        "    '''a function which returns the length of text'''\n",
        "    if(len(text) > 500):\n",
        "        return 500\n",
        "    return len(text)\n",
        "\n",
        "df['length'] = df['content'].apply(length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "AfOXeUwJvph7",
        "outputId": "02315d92-5b3b-41a0-cda5-c7e41237266f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.rcParams['figure.figsize'] = (18.0, 6.0)\n",
        "bins = 150\n",
        "plt.hist(df[df['label'] == 1]['length'], alpha = 0.8, bins=bins, label='Tích cực', color =\"green\")\n",
        "plt.hist(df[df['label'] == 0]['length'], alpha = 0.8, bins=bins, label='Tiêu cực', color =\"red\")\n",
        "plt.xlabel('Độ dài')\n",
        "plt.ylabel('Số lượng đánh giá')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlim(0,500)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tb6eAEv1gQe"
      },
      "source": [
        "Nhận xét: Trung bình số lượng đánh giá tiêu cực nhiều hơn tích cực có cùng độ dài\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP7w8287FkWr"
      },
      "source": [
        "#Tiền xử lý"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrN-KvlMV099"
      },
      "source": [
        " - Các hàm để phục vụ tiền xử lý"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZJb4LuhFii7"
      },
      "outputs": [],
      "source": [
        "#Chuẩn hóa unicode sang chuẩn unicode dựng sẵn\n",
        "def covert_unicode(txt):\n",
        "    return re.sub(\n",
        "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
        "        lambda x: dicchar[x.group()], txt)\n",
        "\n",
        "#Xử lý từ viết tắt\n",
        "def replace_acronyms(txt):\n",
        "  pat = re.compile(r\"\\b(%s)\\b\" % \"|\".join(acronyms))\n",
        "  txt = pat.sub(lambda m: acronyms.get(m.group()), txt)\n",
        "  return txt\n",
        "\n",
        "#Xử lý các từ lặp\n",
        "def remove_loop_char(txt):\n",
        "  txt = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), str(txt), flags=re.IGNORECASE)\n",
        "  txt = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',txt)\n",
        "  return txt\n",
        "\n",
        "#Xử lý các từ dừng\n",
        "def remove_stopwords(txt):\n",
        "  split_words = txt.split()\n",
        "  final_txt = []\n",
        "  for ch in split_words:\n",
        "    if ch not in stopwords:\n",
        "      final_txt.append(ch)\n",
        "  return \" \".join(final_txt)\n",
        "\n",
        "#Xử lý dấu câu\n",
        "def split_punctuations(txt):\n",
        "    punctuations = '@#!?+&*[]-%:/();$=><|{}^_' + \"'`\"\n",
        "    for p in punctuations:\n",
        "      txt = txt.replace(p, f' {p} ')\n",
        "    return txt\n",
        "\n",
        "#Tiền xử lý \n",
        "def preProcessing(txt):\n",
        "  txt = txt.lower()\n",
        "  #Xóa các kí tự xuống dòng\n",
        "  txt = \" \".join(re.sub(\"\\n\", \" \", txt).split())\n",
        "  #Xử lý dấu câu\n",
        "  txt = split_punctuations(txt)\n",
        "  #Thay thế các từ viết tắt\n",
        "  txt = replace_acronyms(txt)\n",
        "  #Xóa các kí tự lặp\n",
        "  txt = remove_loop_char(txt)\n",
        "  #Tách từ\n",
        "  txt = ViTokenizer.tokenize(txt)\n",
        "  #Xóa từ dừng\n",
        "  # txt = remove_stopwords(txt)\n",
        "  #Chuẩn hóa sang 1 kiểu unicode\n",
        "  txt = covert_unicode(txt)\n",
        "  txt = txt.lower()\n",
        "  # Xóa bớt các khoảng trắng thừa\n",
        "  return \" \".join(txt.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc85D5jizbDA"
      },
      "outputs": [],
      "source": [
        "#Tiền xử lý\n",
        "df['content_clean'] = df['content'].apply(preProcessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbhBmZoLX6hx"
      },
      "source": [
        "- Phân chia tập dữ liệu huấn luyện và test bằng nghi thức Hold-out tỉ lệ 7/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ovlqLpWYDZP"
      },
      "outputs": [],
      "source": [
        "X, y = df['content_clean'], df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EATSgZYVRNy",
        "outputId": "396d3f94-e02f-435a-a9e9-4a8087c2c1cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlc9wetiwlZ"
      },
      "source": [
        "Vector hóa văn bảng bằng CountVectorizer và TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8oPEE0jiGAt"
      },
      "outputs": [],
      "source": [
        "#Hàm chuyển dữ liệu train và test thành các vector dùng CountVectorizer và TfidfVectorizer\n",
        "def count_vector(data_train, data_test):\n",
        "    count_vectorizer = CountVectorizer(max_features=5000)\n",
        "    vector_train = count_vectorizer.fit_transform(data_train)\n",
        "    vector_test = count_vectorizer.transform(data_test)\n",
        "    return count_vectorizer, vector_train, vector_test\n",
        "\n",
        "def tfidf_vector(data_train, data_test):\n",
        "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1, use_idf=True)\n",
        "    vector_train = tfidf_vectorizer.fit_transform(data_train)\n",
        "    vector_test = tfidf_vectorizer.transform(data_test)\n",
        "    return tfidf_vectorizer, vector_train, vector_test\n",
        "\n",
        "#Tạo ra vector cho tập train và test với CountVectorizer\n",
        "count_vector, X_train_Count, X_test_Count = count_vector(X_train, X_test)\n",
        "#Tạo ra vector cho tập train và test với TfidfVectorizer\n",
        "tf_idf, X_train_tfidf, X_test_tfidf = tfidf_vector(X_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTvwsZSo7T0R"
      },
      "source": [
        "#Lưu lại model vector hóa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8SqT0ym0VpC"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"vectorizes.pkl\", \"wb\") as f:\n",
        "  pickle.dump((count_vector, tf_idf), f)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JGZtO-lXtQV"
      },
      "source": [
        "#Xây dựng mô hình\n",
        "  - Với Naives Bayes Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZnsCiRXXtsc",
        "outputId": "b0b53591-3d1c-4f21-a62f-ed97eaa12e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Độ chính xác với CountVectorizer: 0.834\n",
            "MultinomialNB()\n",
            "Độ chính xác với TfidfVectorizer: 0.848\n"
          ]
        }
      ],
      "source": [
        "bayes_model_cv = MultinomialNB()\n",
        "bayes_model_cv.fit(X_train_Count, y_train)\n",
        "y_bayes_pred = bayes_model_cv.predict(X_test_Count)\n",
        "print('Độ chính xác với CountVectorizer: %.3f' % accuracy_score(y_test, y_bayes_pred))\n",
        "\n",
        "bayes_model_tf = MultinomialNB()\n",
        "bayes_model_tf.fit(X_train_tfidf, y_train)\n",
        "y_bayes_pred = bayes_model_tf.predict(X_test_tfidf)\n",
        "\n",
        "print('Độ chính xác với TfidfVectorizer: %.3f' % accuracy_score(y_test, y_bayes_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwoinL1b7pi2"
      },
      "outputs": [],
      "source": [
        "#Lưu model bayes lại\n",
        "with open(\"bayes_model.pkl\", \"wb\") as f:\n",
        "  pickle.dump((bayes_model_cv, bayes_model_tf), f)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzGjOqoFwwkS"
      },
      "source": [
        "- Với SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2DdCo2pwv3n",
        "outputId": "e13bf89a-5ef1-4b82-f232-e114df6baa51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Độ chính xác với CountVectorizer: 0.828\n",
            "Độ chính xác với TfidfVectorizer: 0.864\n"
          ]
        }
      ],
      "source": [
        "svm_model_cv = svm.SVC(kernel='linear', C=1.3)\n",
        "svm_model_cv.fit(X_train_Count, y_train)\n",
        "y_svm_pred = svm_model_cv.predict(X_test_Count)\n",
        "print('Độ chính xác với CountVectorizer: %.3f' % accuracy_score(y_test, y_svm_pred))\n",
        "\n",
        "svm_model_tf = svm.SVC(kernel='linear', C=1.3)\n",
        "svm_model_tf.fit(X_train_tfidf, y_train)\n",
        "y_svm_pred = svm_model_tf.predict(X_test_tfidf)\n",
        "print('Độ chính xác với TfidfVectorizer: %.3f' % accuracy_score(y_test, y_svm_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhAj8GLt8UqD"
      },
      "outputs": [],
      "source": [
        "#Lưu model SVM lại\n",
        "with open(\"svm_model.pkl\", \"wb\") as f:\n",
        "  pickle.dump((svm_model_cv, svm_model_tf), f)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_aeWL-knKPF"
      },
      "source": [
        "- Với Logistic Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui5Idvyq1oYO",
        "outputId": "70fa0735-af4a-4b72-e88f-333b3593ea1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Độ chính xác với CountVectorizer: 0.840\n",
            "Độ chính xác với TfidfVectorizer: 0.865\n"
          ]
        }
      ],
      "source": [
        "linear_model_cv = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000)\n",
        "linear_model_cv.fit(X_train_Count, y_train)\n",
        "y_linear_pred = linear_model_cv.predict(X_test_Count)\n",
        "print('Độ chính xác với CountVectorizer: %.3f' % accuracy_score(y_test, y_linear_pred))\n",
        "\n",
        "linear_model_tf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000)\n",
        "linear_model_tf.fit(X_train_tfidf, y_train)\n",
        "y_linear_pred = linear_model_tf.predict(X_test_tfidf)\n",
        "print('Độ chính xác với TfidfVectorizer: %.3f' % accuracy_score(y_test, y_linear_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTlANTXX8hzC"
      },
      "outputs": [],
      "source": [
        "#Lưu model logistic lại\n",
        "with open(\"linear_model.pkl\", \"wb\") as f:\n",
        "  pickle.dump((linear_model_cv, linear_model_tf), f)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEdoRp35nQ7B"
      },
      "source": [
        "Ta có thể thấy được độ chính xác khi sử dụng TfidfVectorizer luôn cao hơn so với khi sử dụng CountVectorizer. Và mô hình SVM cùng với Logisric Regression cho độ chính xác cao nhất khi đạt đến khoảng 86.5%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcWC57Ctu9oP"
      },
      "source": [
        "# Mô hình DeepLearing - Phobert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6NnAi3DpDDu"
      },
      "source": [
        "Tham khảo từ nguồn https://viblo.asia/p/bert-roberta-phobert-bertweet-ung-dung-state-of-the-art-pre-trained-model-cho-bai-toan-phan-loai-van-ban-4P856PEWZY3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZU-J431rDlM"
      },
      "source": [
        "Load từ điển có sẵn của Phobert. Bpe giúp ta enconde(Chuyển 1 câu thành 1 mảng các subword. vocab giúp ánh xạ ngược các subword thành id trong bộ từ điển của Phobert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrRXZunqyzgc"
      },
      "outputs": [],
      "source": [
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--bpe-codes', \n",
        "    default=\"/content/PhoBERT_base_transformers/bpe.codes\",\n",
        "    required=False,\n",
        "    type=str,\n",
        "    help='path to fastBPE BPE'\n",
        ")\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "bpe = fastBPE(args)\n",
        "\n",
        "# Load the dictionary\n",
        "vocab = Dictionary()\n",
        "vocab.add_from_file(\"/content/PhoBERT_base_transformers/dict.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2NB-szJpOkV"
      },
      "source": [
        "Vì mô hình Phobert có quá trình tiền xử lý khác với các mô hình thông thường nên ta cần tiền xử lý khác đi 1 chút"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klyKvSnRZ_mx"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(txt):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r\" \", txt)\n",
        "\n",
        "def fix_number(txt):\n",
        "    txt = re.sub(r'(?<=\\d)(?=[^\\d\\s])|(?<=[^\\d\\s])(?=\\d)', ' ', txt)\n",
        "    return txt\n",
        "\n",
        "def preProcessing(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace(':)',' ')\n",
        "    txt = txt.replace(':))',' ')\n",
        "    txt = txt.replace(':)))',' ')\n",
        "    txt = txt.replace('=)',' ')\n",
        "    txt = txt.replace('=))',' ')\n",
        "    txt = txt.replace('=)))',' ')\n",
        "    txt = txt.replace(':(',' ')\n",
        "    txt = txt.replace(':((',' ')\n",
        "    txt = txt.replace(':(((',' ')\n",
        "    txt = txt.replace('...',' . ')\n",
        "    txt = split_punctuations(txt)\n",
        "    txt = fix_number(txt)\n",
        "    #Thay thế các từ viết tắt\n",
        "    txt = replace_acronyms(txt)\n",
        "    txt = remove_emoji(txt)\n",
        "    txt = ViTokenizer.tokenize(txt)\n",
        "    txt = txt.lower()\n",
        "    return txt\n",
        "\n",
        "df['clean_content'] = df['content'].apply(preProcessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YStDxxbrhIS"
      },
      "source": [
        "Tiến hành phân chia tập dữ liệu bằng Hold-out và bắt đầu encode. Với MAX_LEN = 84 có nghĩa là các câu có độ dài lớn hơn sẽ bị cắt còn 124 từ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGhANQpV0NNB"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 84\n",
        "\n",
        "X = df['clean_content']\n",
        "y = df['label'].to_list()\n",
        "\n",
        "train_sents, val_sents, train_labels, val_labels = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "#Tiến hành encode\n",
        "train_ids = []\n",
        "val_ids = []\n",
        "\n",
        "for sent in train_sents:\n",
        "    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n",
        "    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n",
        "    train_ids.append(encoded_sent)\n",
        "\n",
        "for sent in val_sents:\n",
        "    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n",
        "    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n",
        "    val_ids.append(encoded_sent)\n",
        "\n",
        "#List các id\n",
        "train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "val_ids = pad_sequences(val_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYeqyh-MsVLK"
      },
      "source": [
        "Ta tiến hành tạo các mask là mảng gồm các số 0 1 nhằm kiểm tra xem các giá trị nào của chuỗi đã được padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKhGNeZR1q9Y"
      },
      "outputs": [],
      "source": [
        "train_masks = []\n",
        "for sent in train_ids:\n",
        "    mask = [int(token_id > 0) for token_id in sent]\n",
        "    train_masks.append(mask)\n",
        "\n",
        "val_masks = []\n",
        "for sent in val_ids:\n",
        "    mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    val_masks.append(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzqbQqg-sk3a"
      },
      "source": [
        "Chuyển dữ liệu sang Tensor và sử dụng DataLoader của torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knlhDFqr2KQZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "train_inputs = torch.tensor(train_ids)\n",
        "val_inputs = torch.tensor(val_ids)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = SequentialSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYju8W4psuLn"
      },
      "source": [
        "Ta tiến hành load mô hình từ Phobert (Mô hình này chưa qua huấn luyện với tập dữ liệu hiện tại)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLVl8lSS3Q7k"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW, BertForSequenceClassification\n",
        "\n",
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 2, output_hidden_states=False,\n",
        ")\n",
        "BERT_SA = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/PhoBERT_base_transformers/model.bin\", \n",
        "    config=config\n",
        ")\n",
        "\n",
        "BERT_SA.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_0ch_aTtM3i"
      },
      "source": [
        "Hoặc ta có thể load mô hình Phobert mà đã qua huấn luyện với tập dữ liệu hiện tại"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXk8QAhrtNpl",
        "outputId": "83f1693a-d124-4e6c-c3c7-05c7da07caf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(258, 768)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Chỉnh đường dẫn lại theo file đi kèm\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW, BertForSequenceClassification\n",
        "\n",
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 2, output_hidden_states=False,\n",
        ")\n",
        "BERT_SA = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/model_phobert/pytorch_model.bin\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "BERT_SA.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4DDQ2ltp_R"
      },
      "source": [
        "Hàm để huấn luyện "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nBn34RHZyZe"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(logits, labels):\n",
        "    preds = []\n",
        "    for line in logits:\n",
        "        preds.append(torch.argmax(line).cpu().numpy())\n",
        "    return accuracy_score(preds, labels.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7O0tsf0uMy3"
      },
      "outputs": [],
      "source": [
        "def train_model(model):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    acc = []\n",
        "    for batch in train_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        BERT_SA.zero_grad()\n",
        "        outputs = model(b_input_ids, \n",
        "            token_type_ids=None, \n",
        "            attention_mask=b_input_mask, \n",
        "            labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        acc.append(flat_accuracy(logits, b_labels))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    return train_loss, round(np.mean(acc), 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG-pQ9PltutB"
      },
      "source": [
        "Tiến hành huấn luyện mô hình. Nếu ta load mô hình đã qua huấn luyện thì có thể bỏ qua đoạn này"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3URSzVY352R"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "device = 'cuda'\n",
        "epochs = 4\n",
        "\n",
        "param_optimizer = list(BERT_SA.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(BERT_SA.parameters(), lr=1e-5, correct_bias=False)\n",
        "train_loss_ = []\n",
        "test_loss_ = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    begin_time = time.time()\n",
        "    loss, acc = train_model(BERT_SA)\n",
        "    done_time = time.time() - begin_time\n",
        "    print(f\"Epoch {epoch + 1}: {round(done_time)} seconds - loss {round(loss, 3)} - accuracy {acc}\")\n",
        "    train_loss_.append([loss, acc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evD2JRhFt1Jc"
      },
      "source": [
        "Tiến hành dự đoán trên tập test. Kết quả trả về sẽ là 1 mảng [a, b] trong đó a và b là xác xuất của dữ liệu đó đối với nhãn 0 và 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0J45lvf0ZUn"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "preds = []\n",
        "for batch in val_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    with torch.no_grad():\n",
        "        pred=BERT_SA(b_input_ids,token_type_ids=None,attention_mask=b_input_mask)\n",
        "        preds.append(pred[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-AjkraEui7u"
      },
      "source": [
        "Dùng hàm argmax của numpy để chuyển đổi mảng [a,b] thành nhãn 0 hay là 1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa3Am_PM2ioY"
      },
      "outputs": [],
      "source": [
        "lab = []\n",
        "for line in preds:\n",
        "  for i in line:\n",
        "    predicts = i.to('cuda').detach().numpy().copy()\n",
        "    lab.append(np.argmax(predicts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iztmWKxZuwfJ"
      },
      "source": [
        "Đánh giá mô hình "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe3H87tK3KWn",
        "outputId": "cd2c5a0b-a238-4860-dfc4-ba589d585b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8453192026242745\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(val_labels.tolist(), lab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DWCVrbau3pY"
      },
      "source": [
        "Đoạn code này sẽ xóa mô hình để tránh việc bị lỗi. Nên chạy đoạn code này sau khi đã tạo mô hình trên Colab hoặc Kaggle tránh việc gây lỗi "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hbYqRgOUzvS"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "del BERT_SA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oM2xnwLWCOM",
        "outputId": "13d7236b-7029-4d05-fb89-91934f8ac71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MSSV_TenSVVietLien_Reviews_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
